# Random Tree

- bootstrapped dataset 有放回的取样
- 每一步，只使用 variable 的 subset，使用其中最能够用于区分的那一个variable。然后在下一个时刻，我们在除了这个 variable 以外的 variable 里选取 subset：这个subset size是一个可以调节的hyper parameter
- 我们可以把没有被选中的样本当作测试，得到 out of bag error

# Cross Validate

我们想要 maximize dataset 可用于 training 和 testing 的数量

k fold 就是把数据 k 等分，然后运行k次训练，每次使用一个不同的 $\frac{1}{k}$ 的数据作为 testing set。然后我们需要 average 这 k 次训练的结果

# Epoch & batch

Epoch 是训练过程中看了多少遍数据
batch 是一部分的数据，训练时看过整个 batch 之后根据 error 就会更新 weights

较小的 batch size 允许模型更快地学习，但由于梯度方差（gradient variance）较大，可能会引入更多噪音，而较大的批次可以提供更高的学习稳定性，但代价是学得慢

# Quantifying Meibomian Gland Morphology Using Deep Learning

Developed an automated method for analyzing Meibomian gland morphology using deep learning with instance segmentation techniques.

需要提到数据集的规模：Utilized a dataset of 1,443 infrared meibography images of human subjects, manually annotated for individual gland regions and "ghost glands."
实例分割：Applied a deep convolutional neural network (CNN) to perform instance segmentation of individual glands and identify ghost glands with high precision.

验证集结果：Achieved a mean intersection over union (mean IU) score of 58.4% for upper eyelid images and 68.0% for lower eyelid images.
The ghost gland identification model achieved 84.7% sensitivity and 72.5% specificity for upper eyelids, and 84.1% sensitivity and 70.8% specificity for lower eyelids.

形态学研究：Extracted key morphological features, including gland length, width, tortuosity, and local contrast, with a support vector machine (SVM) to analyze associations with ghost glands.
形态学研究的成果：Demonstrated that low gland local contrast was the primary indicator of ghost glands, leading to improved diagnostic accuracy for Meibomian gland dysfunction.

总的成果：Reduced the time needed for image analysis to 0.32 seconds per image, enhancing efficiency for large-scale clinical evaluations.

Segmentation 有三种
- Object Detection：一般是 bounding box 框起来
- Semantic Segmentation：同一类的元素，CNN 发现轮廓
- Instance Segmentation：区分每一个元素的边缘轮廓，知道哪里是一个元素
- Mask R-CNN：先 object detection (RPN)，再 mask 这个部分来找轮廓（FCN）
- 如果只使用 FCN，每一个 channel 表示一个找到的物体，这样会有 mask representation 很低效的问题。所以我们可以分成两个部分：kernel branch 和 feature branch，我们就可以有很快的 Mask NMS
- Matrix Non-maximum Suppression (NMS) 去掉 duplicated predictions，可以并行
- AP Average Precision

# Facial Recognition

检测人脸 bounding box：https://github.com/opencv/opencv/blob/4.x/data/haarcascades/haarcascade_frontalface_default.xml

获得视频输入

```python
cap = cv.VideoCapture(0) # the first camera
# alternative: load the video
# cap = cv.VideoCapture('test.mp4') 

while cap.isOpened():
    flag, frame = cap.read()
    if not flag: break
```

把图片变成灰度的数组（用于训练）

```python
PIL_img = Image.open(path).convert('L')
img_numpy = np.array(PIL_img, 'uint8')
```

训练模型

```python
recognizer = cv2.face.LBPHFaceRecognizer_create()
recognizer.train(faces, np.array(ids))
recognizer.write('trainer/trainer.yml')
```

读取训练的模型

```python
recognizer = cv2.face.LBPHFaceRecognizer_create()
recognizer.read('trainer/trainer.yml')
ids, confidence = recognizer.predict(gray[y:y+h, x:x+w])
# 这里 confidence 越低说明的是认识的人？为什么
```

通过 rtmp streaming 获取远程的摄像头

```python
cam = cv2.VideoCapture("rtmp://58.200.131.2:1935/livetv/cctv5")
```

## Viola Jones Algorithm (2001)

核心观点是找到对于一个区域，上下/左右分成2/3块，然后把和相减。

加速的方法：每一个位置都存的是以它为右下角的和（prefix sum）