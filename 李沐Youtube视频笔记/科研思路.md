- 避免做 pretrain，尽量用在大数据上训练的 base model，只做下游任务，或者 adapter (plug and play)，或者 fine tuning
- 可以做新的 dataset，evaluate 新的或者已有的 dataset，做某个新的领域的综述
- 可以做 efficient modelling:
  - quantization: 32 bit float to 8 bit int
  - pruning: removing less important weights/ neurons
  - distillation: small bot train from a larger model
- Parameter Efficient Fine Tuning:
  - adapter layers: freeze base model, only train a few layers
  - Low-rank adaptation: decompose matrics into low-rank matrics and only fine-tuning them
  - prefix tuning: 在 input embedding 前面 prepend 任务具体的 vectors（类似于 prompt engineering 的训练）