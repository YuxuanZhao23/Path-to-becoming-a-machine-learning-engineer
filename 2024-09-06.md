# Bias & Variance

**Bias** 偏差：提供的 prediction 和 ground truth 之间的差别（是否正确）

**Variance** 方差：提供的 prediction 之间的差别（是否分散）

不管如何采样 D，这个期望值都应该比较小。期望值的期望值也是它本身，因为已经是一个常数了。交叉项都被消掉了因为这三项可以被认为是独立的

$E_D[(y - \hat{f}(x))^2] = E[((f - E[\hat{f}]) + \epsilon - (\hat{f} - E[\hat{f}]))^2] = Bias[\hat{f}]^2 + Var[\hat{f}] + \sigma^2$

- 模型复杂度越低，那么generalization越好，Bias越高（结果不对），Variance越低（结果很聚集），此时是 under fitting
- 模型的复杂度越高，那么generalization越好，Bias越低（结果对了），variance越高（结果很分散，模型拟合了数据的噪音），此时是 over fitting

降低 bias
- 更复杂的模型
- boosting
- stacking

降低 variance
- 更简单的模型
- regularization 使用 $r(\theta)$ 对不同层的weight变得连续平滑（如果差异很大会有惩罚）
- bagging
- stacking

降低噪音
- 统计上不可以降低
- 实践上可以通过改进数据的质量来提升

Ensemble Learning
- 使用多个模型来同时减少 bias 和 variance
- boosting, stacking, bagging

# Bagging (Boostrap AGGrgratING)

- 独立训练n个模型，然后regression是average结果，classification是majority voting
- 训练集长度虽然都为m，但是是有放回的取样，大约有63%（也就是 $1 - \frac{1}{e}$）的example会被sample，可以使用没被选中的来当作validate
- 一个例子是 random forest，通常除了可以随机采样行，也可以采样列，这样可以有效避免过拟合
- 无限增加模型数据，也不会让结果变差，因为只有 variance 下降，bias不会变化
- unstable model 在每个模型给出结果很不一样的时候 bagging 才有改进的空间 $\hat{f}(x) = E[h(x)]$ 比如说 linear regression 的效果就不如 random tree 的 bagging 效果好

# Boosting

- 多个弱模型组合成强一点的模型，模型要按顺序学习
- 下一个模型的学习重点是当前训练出错的结果：会给下一个模型传出错的数据
- AdaBoost, Gradient Boosting Decision Trees (小学习率，小树深度)
- 模型弱和学习率低的时候，增加模型不太会 overfitting
- 提升构建树的速度：XGBoost, lightGBM

# Stacking

- 不同于 bagging，在同样的数据上，训练不同类型的模型
- 不用管模型输出的内容size，直接全部concat
- 最后加一个 dense layer（这里也可以学，所以不是简单的求平均值或者最多投票）
- stacking 本身是降低 variance 的，如果我们做多层的 stacking 我们可以降低 bias，
  
multi-layer stacking 特别容易过拟合
  - 训练集分成两部分，第二层的训练集和第一层的训练集不是耦合在一起
  - repeated k-fold bagging
  - k fold 并重复 n 次，最能避免过拟合，但是花费最高，效果改进不一定明显
  - 时间复杂度 nlk，可以在同一层上并行（并行度nk）

# model tuning

- 控制变量，每次只调整一个 hyper parameters
- 找到重要的超参数
- 学习的结果对哪个超参数很敏感（超参数不同会变得很差）Adam 和 SGD 比较起来，超参数相对没那么敏感，比较大的区间里都会比较好，方便调参
- 调参的时候一定要做好笔记，不然会忘掉之前的结果是什么样的（training log 和 hyperparameters）：tensorboard, weights & bias
- 重现是很困难的：环境（硬件，lib），代码，seed
- 如果seed一换结果就抖动得很厉害，那么一般是数据出了问题，dropout
- 机器自动调参比用人要便宜很多：机器1000次trials来说能击败绝大多数人

AutoML
- Hyperparameter optimization (HPO)
- Neural Architecture Search (NAS)

# HPO

search space: 
- 从小到大的网络
- learning rate [1e-6, 1e-1] log-uniform 可以在很大的区间选取数字，不会取不到其中的一些小范围的数
- batch size [8, 16, ..., 512] 因为线程的数字往往是2的倍数，方便做并行
- momentum [0.85: 0.95]
- weight decay: [1e-6, 1e-2] log uniform
- detector: [faster-rcnn, ssd, yolo-v3, center-net]
- 每增加一种hyperparameter，搜索空间是指数增加的，所以需要经验来选一个合理的区间
- 可能就试几个 top performers 就好，并不用真的试所有的组合

## black box

一个超参数组合进去，然后训练的结果matrices来决定好不好，适用于任何机器学习的算法

Grid Search
- 穷举所有的超参数组合
- 保证找到最优结果
- curse of dimensionality

Random Search
- 随机选取 n 次超参数组合
  - 可以在给定时间内运行
  - 最佳结果已经不再显著变化
  - 也就是说不需要 hard code 一个 n
- 实际上是一个非常有效的方法，成本低，不怎么需要优化

Bayesian Optimization BO
- 学习从 **超参数** 到目标函数的转换函数
- 可以对比一下实际的 model 学习的是 **数据** 到目标函数的转换函数
- Surrogate Model
  - 使用 probabilistic regression model（random forest, Gaussian process）去拟合
  - 所以我们时时会有整个search space 的预测值和对应的置信度
  - 我们下一个采样的地方在 Acquisition Max
    - 这个地方我们置信度很低，同时潜在的目标函数比较高的地方
    - Trade off exploration and exploitation
- 一开始和 random search 差不多，后期会比 random search 好一点
- 计算是 sequential，不像随机是可以全部并行的

## Multi-fidelity：真的训练一个任务太贵了

- subsampled datasets上训练就好
- 减少model size(less layers, channels)
- earlier stopping 不好的结果

Successive Halving
- 选 n 个超参数组合，训练 m 次，一般来说 n 要大一点，m 要小一点
- 每个时刻放弃掉一半表现不好的组合，训练次数变成上一次的4倍
- 不靠谱的淘汰，靠谱的多给点资源（每个时刻的总计算开销其实差不多）
- 倒推来决定 n（多少budget） 和 m（最后需要扫多少次）

Hyperband
- 从n很大，m很小开始，跑 Successive Halving
- 然后淘汰一半表现差的n，m两倍
- 这种方法对于 n 和 m 的选取不那么敏感了：n 代表的是 exploration，m 代表的是 exploitation

# Neural Architecture Search NAS

- topological structure: resnet, mobilenet, layer 数量
- individual layer: kernel size, convolutional layer's channel 数量，dense/recurrent layer's hidden_outputs 数量
- 用 NAS 来自动化设计神经网络
  - specify search space
  - explore search space
  - estimate performance
- Reinforcement Learning
  - RNN 生成一系列的 token 来 config model architecture
  - 用这个 config 训练完模型之后，用 matrices 结果来 reinforce RNN
  - RL 非常非常贵，可以用 estimate performance，parameter sharing (EAS, ENAS) 来优化一下计算量
- One-shot 稍微实用一点
  - 一个巨大的模型包含了很多子模型，训练完了之后我们可以既得到子模型参数，也得到用于训练子模型的超参数
  - 有很多时候只需要知道 candidate ranking 就行，不需要训练到收敛
  - 例子：Differentiable Architecture Search
    - 每一层有多个候选，使用 softmax 来选择，最后选出来一个通路（每一层有最大候选参数的模型是我们要选择的，也就是这个最接近1，同一层别的都是接近0）
    - 改进：DARTS 温度让参数会更趋于0或1
- 最实用的 Scaling CNNs: EfficientNet
  - CNN 可更改的东西有：多少 layer，多少 output channels，输入图片的分辨率
  - 我要三个连着一起动，而不是控制变量
  - depth 乘上 $\alpha ^ \phi$，width 乘上 $\beta ^ \phi$，resolution 乘上 $\gamma ^ \phi$，保持 $\alpha \beta ^ 2 \gamma ^ 2 \approx 2$ 因为我们想要每次时间复杂度增加一倍，主要调整 $\phi$ 就好
- 研究方向：
  - explainability
  - edge devices 
    - phone
      - 优点：latency, privacy
      - CPU/ GPU/ DSP/ Battery
      - minimize $loss \times log(latency)^\beta$
  - auto the whole ML