# remark 2.1.1

2.1 里面定义的 log likelihood 

$$l(\theta) = log L(\theta) = \sum\limits_{i=1}^{n}y^{(i)} log (h(x^{(i)})) + (1 - y^{(i)})log(1 - h(x^{(i)})$$

定义 $t = \theta^Tx$ 代入 $h_\theta(x) = \frac{1}{1 + e^{-\theta^Tx}}$ 可以得到 $h_\theta(x) = \frac{1}{1 + e^{-t}}$，将其代入到 log likelihood 得到（第三行：因为 $log(a^b) = b * log(a)$ ，所以有 $log \frac{1}{x} = - log (x)$）

$$
\begin{aligned}
l(\theta) &= \sum\limits_{i=1}^{n}y^{(i)} log \frac{1}{1 + e^{-t}} + (1 - y^{(i)})log \frac{1 + e^{-t} - 1}{1 + e^{-t}}\\ &= \sum\limits_{i=1}^{n}y^{(i)} log \frac{1}{1 + e^{-t}} + (1 - y^{(i)})log \frac{1}{1 + e^{t}}\\ &= -\sum\limits_{i=1}^{n}y^{(i)} log (1 + e^{-t}) - (1 - y^{(i)}) log (1 + e^{t})
\end{aligned}$$



求导 

$$
\begin{aligned}
\frac{\partial l(\theta)}{\partial \theta} &= -\frac{\partial l_{logistic}(t, y)}{\partial t} \frac{\partial t}{\partial \theta}\\ &= (- y \frac{-e^{-t}}{1 + e^{-t}} - (1-y)\frac{e^t}{1 + e^{t}})x\\ &= (- y \frac{-e^{-t}}{1 + e^{-t}} - (1-y)\frac{1}{1 + e^{-t}})x\\ &= (\frac{y e ^{-t} - 1 + y}{1 + e^{-t}})x\\ &= (y - \frac{1}{1 + e^{-t}})x\\ &= (y - h_\theta(x))x
\end{aligned}$$