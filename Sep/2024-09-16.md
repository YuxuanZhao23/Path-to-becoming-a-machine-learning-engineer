# CNN followup

- 在没有 batch normalization 之前，很深的网络基本上没办法 converge
- 网络中的 shortcut 其实是方便 gradient flow 回来，是 gradient highway

# Neural Network

- one to one: CNN/ classifier
- one to many: Image Captioning
- many to one: Sentiment Classification
- many to many: language translate, video classification on frame level

# Recurrent Neural Network

$h_t = f_W(h_{t-1}, x_t)$，h 是一个 internal state

vanilla RNN

$h_t = tanh(W_{hh}h_{t-1} + W_{xh}x_t)$

$y_t = W_{hy}h_t$

因为 W 是共用的，所以对于 W 的更新将会是每一个时刻的更新之和。Loss 是每一个时刻单独的 y 的 loss，总的 loss 是所有的 loss 之和

Sequence to Sequence: many to one (encode) + one to many (decode)

# Language modelling

- 并不是直接选择概率最高的词，而是 sample 一个词
- 虽然模型只是在预测下一个词，但是实际上模型会学会了某种输入文本的模式：quote，句子长度，latex，代码结构，注释等等

# Other usages

- image caption: CNN + RNN，也可以增加 localize
- visual question answer：多选题

# LSTM

vanilla 是只有一个 hidden state，我们可以把这个 hidden state 传进另一个 RNN 里面，Multilayer RNN 就是这样的。LSTM就有三个 sigmoid 和一个 tanh

- sigmoid i (input gate)：是否write
- sigmoid f (forget gate)：是否erase，element-wise，用于避免gradient exploding 和 vanishing
- sigmoid o (ouput gate)：reveal多少
- tanh g (gate)：write多少
- LSTM 也有一个 cell state gradient highway 就类似于 ResNet

# Gradient Flow

我们会发现 gradient 会乘非常多次 $W^T$ 和重复非常多次 tanh，所以对于大于 1 的 gradient 来说会 exploding，对于小于 1 的 gradient 会 vanishing

- gradient clipping：scale gradient if too big
- LSTM for vanishing gradient

# Semantic Segmentation

- No object, just pixel
- not differentiate instances
- Brute Force 把图片切成小块，每个小块进行 CNN 分类行不行？这样计算量太大了，完全不实用
- 我们可以输出一个 W * H * C 的矩阵，C 是所有的类，里面每一个数字是该像素是某一类的概率。如何训练呢？需要有人去手动 classify 每个像素才行。同时这个模型也非常贵
- 实用一点的呢？downsample (stride convolution/ max pooling) 之后 upsample 

# Upsample

- nearest unpooling：全部填同一个数字
- bed of nails unpooling：左上角同一个数字，其他都填0
- max unpooling：记住 downsample 的时候最大值是哪一个，现在放回去，其他还是填0
- transpose convolution/ deconvolution/ upconvolution/ fractionally strided Convolution/ Backward Strided Convolution：中间有 overlap 的地方直接加起来

# Classification + Localization/ Human Pose Estimation

- 一个 network 最后的 vector 经过一个 FC 得到 class，同时经过另一个 FC 得到 bounding box 位置：会不会 box 和 class 不是同一个 class？现实中可能性不大，不过可以 specify box 对应的 class

# Loss

- 当我们需要 category 作为结果的时候，我们一般可以使用：cross entropy loss, softmax loss, SVM margin type loss
- 当我们需要一些连续值的时候，我们可以使用 L1/ L2 loss，我们可以统称为 regression loss

# Object Detection

- 不同之处在于你不提前知道有多少个 expected objects
- 暴力 sliding window: 怎么选择 crop？有不同的位置和大小。不可行
- Regional proposal: 传统 signaling processing 很快建议一些需要看的位置（blobby region）一个例子是 selective search 能在几秒钟给出 1000 个位置
- R-CNN：使用 proposal 来找到 Regions of Interest，全部 wrap 成相同的大小进入 CNN 之后进入 SVM。网络会稍微调整这些 bounding box 的位置和大小
  - 训练很慢，需要很多磁盘空间
  - inference 很慢，一张图片用 VGG16 需要 47 秒
- Fast R-CNN
  - 依然使用 proposal，但是现在不再基于原始的图片而是基于 CNN feature map，这样可以节约很多计算
  - 之后使用 RoI Pooling, FC, Linear + softmax
- Faster CNN
  - 使用 Region Proposal Network 来预测 proposal
  - 需要基于以下 4 种 loss 来训练：RPN classify object, RPN box coordinate, final classification, final box coordinates
- YOLO/ SSD
  - 不要 proposal 的方法，而是把图片切分成 7 x 7 grid，对于每一个位置有五个参数 dx, dy, dh, dw, confidence 预测是 C 种 class 的其中哪一种
  - SSD（single shot）速度更快，但是 Faster R-CNN 预测更准确

# Instance Segmentation (pose)

Mask R-CNN：CNN -> RoI Align -> Conv -> Conv -> Mask for C classes
                            |-> classification

# cross entropy loss

$\sum CE_{predict}-ln(predict)$

我们可以计算 Squared Residuals $\sum (\hat{y} - y)^2$ 为什么我们还需要 cross entropy loss？

因为 cross entropy 会严厉惩罚很差的 prediction，在靠近 0 的时候会 exploding。这样的话，学习的速度能够加快