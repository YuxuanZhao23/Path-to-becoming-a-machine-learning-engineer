# Locally Weighted

什么情况下使用：有很多数据，但是数据的维度很小（feature的数量很少）具体来说就是2-4个feature，几百上千的个数，不适用于百万级的数据（KD Tree 之类的会好一点）

# why least square?

- likelihood of the parameters $L(\theta)$，假定 fixed data, $\theta$ 是会变化的
- probability of the data $p(y | x; \theta)$
- 选择 $\theta$ 来最小化 least square error 等同于寻找最大的 likelihood estimate（基于error是IID和gaussian distributed的假设）
- 一般来说不会真的有完全IID的情况，但是想象成IID一般也不会影响结果太多

# classification

- 直接使用 linear regression 到 binary classification 的效果是不好的，因为会受到我们选用的 coordinate 和 outlier 的很大影响。同时我们只想要0-1的输出
- 所以我们使用的是 logistic regression，也就是使用的 sigmoid function $g(x) = \frac{1}{1 + e ^ {-x}}$
- 将0和1的情况写在一起：$p(y|x;\theta) = h(x)^y(1-h(x))^{1-y}$