# Supervised Learning

- Regression: house price
- Classification: probability

# Support Vector Machine (SVM)

- infinite number/ dimension of input feature

# In Practice

我们需要经常做出各种决定，是否需要收集更多的数据？收集数据的格式，内容，类型？算法，超参数，训练时间？所以我们需要把经验主义的黑魔法变成系统性工程过程

# adversarial attack

极小的变化就能使模型有很高的自信认定另一个结果，对于以下的网络都有影响

- Linear Model: logistic regression, softmax regression, SVM
- Decision Tree
- Nearest Neighbors
- Neural Networks
- Reinforcement Learning

这种变化并不是 random noise，即使我们重新训练模型，同样的攻击仍然会奏效。我们使用 clean example 加上这个 mapping，也会同样引导出相同class的错误。这种错误可能更多来自于 underfitting 而不是 overfitting。同一个数据集/任务的不同模型很可能会被同一个 adversarial attack 所欺骗，我们可以训练一个 accessible differentiable model，然后做一个 adversarial example 是适用于另一个模型的

模型的 weight 对于结果来说是非常 non-linear 的，所以训练起来很困难。但是模型的输入输出的表现实际上非常 linear，所以 piecewise 并不会分的很复杂

对少量像素进行改变其实不太会影响 L2 normalization，但是所表达的内涵可能就已经有很大的不同

所以我们可以使用 fast gradient sign method，主要是限制了 $||\tilde{x} - x||_\infty \leq \epsilon$ 也就是每一个输入都不能改变太多，因为我们想要骗过机器，而不是真的改变 class。现实中更强的方法有 Nicholas Carlini's Attack (Adam optimizer)

就像马算数其实是通过看周围的人的反应一样，我们的模型设计和数据输入是有很大 bias 的，所以模型很可能在学习一些与我们期望值不同的东西来做判断。如果我们生成一些 Gaussian Noise 给 CIFAR 模型，这些模型很难认为这些噪音是 equally 可能是所有的 class，反而会很坚定认为是某一个 class

反抗 adversarial attack 是很难的，而表现最好的是基于 adversarially example 来训练 neural networks

Adversarial training 可以用作 regularization 来让模型表现更稳定，也可以帮助 unsupervised 变成 semi- supervised learning

大部分的 model-based optimization 都很难应对 out-of-domain input