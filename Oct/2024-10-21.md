# data batch transforms using Apache Spark on Amazon EMR

1. Launch Amazon Elastic MapReduce: create and include Spark, configure node numbers 可以使用 autoscale，EC2 spot 来减少花费
2. upload date to a S3 bucket
3. submit Spark job: add new step of running Spark python script ```spark-submit --deploy-mode cluster s3://your-bucket/scripts/your_spark_job.py```
4. transform example:
```python
from pyspark.sql import SparkSession

# Initialize Spark Session
spark = SparkSession.builder.appName("BatchTransformJob").getOrCreate()

# Read input data from S3
input_data = "s3://your-bucket/input/data.csv"
df = spark.read.csv(input_data, header=True, inferSchema=True)

# Perform transformation (e.g., filtering rows, adding columns)
transformed_df = df.filter(df['column_name'] > 100).withColumn('new_column', df['column_name'] * 2)

# Write transformed data to S3
output_data = "s3://your-bucket/output/transformed_data"
transformed_df.write.csv(output_data, mode="overwrite", header=True)

# Stop Spark session
spark.stop()
```
5. monitor in Amazon EMR console's steps/ logs and Spark tab
6. Review and verify

ETL - Extract Transform, Load

# SageMaker

SageMaker Data Wrangler: convert, transform, combine raw tabular data
SageMaker Clarify: make training data well balanced, well represented
SageMaker Pipelines: contiuous integration/ continuous deployment

# CloudWatch

- Dashboard: 类似于 splunk，我们可以引入多个直观的 widget
- Alarm: 某个 metric 的一定条件下会发出警告
- Logs: 可以按 group 来查看
- Metrics
- Events: 可以设定成每1分钟就触发一个lambda func，还有event bus
- Synthetics: 定时 ping api 来确保正常运行

# Spark

Spark 是 Hadoop 的替代品。Hadoop 主要用于处理大数据，但是它非常依赖于将数据存放在硬盘里。随着对数据的处理，硬盘的读写成本将变得越来越多。同时它是按 batch 处理的，也就是说尽管使用了分布式的概念，我们也要等上一个 job 完成才能进行下一个 job

Spark 使用了 RDD (Resilient distributed dataset)，使用 RAM 来避免了高昂的硬盘读写，快了100倍。Driver会将大的任务划分然后交给executor

Spark 里面的 data 是以表格形式存在的 (data frame)，然后每一个 node 上面的被称为 partition

Spark 使用了 lazy evaluation，所以代码并不会立刻执行，Spark 会找到最合适的 data flow 来高效完成所有任务

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

tips = spark.read.csv("data/tips.csv", header=True) # data type: DataFrame
tips.show()

tips.createOrReplaceTempView("tips") # create table in database

tips10 = spark.sql("SELECT * FROM tips LIMIT 10")
tips10.show()

tips10_df = tips10.toPandas() # 也可以变成 panda 格式

tips_03 = tips.filter(tips.sex == "Female").filter(tips.day == "Sun")
tips_03.show() # filter 不会执行直到这里 show
```

# Kafka

Kafka 需要某种策略来将不同的信息放到不同的队列(partition)中。使用 partition key 来决定将某一条 record 放到哪一个具体的 partition。

使用 broker 来 host partition，replication factor 是说有多少个 broker 备份。一系列的 partition 存放着相同类型的数据被称为 topic。在某一个具体的 partition 中的位置被称作 offset

# Prometheus

用于 monitor 动态变化的 container，持续监控所有的 service，只要有任何一个 crash 就发出 alert，这样的好处是不需要等到失败影响到终端用户再 backtrack 回去这么困难

在出现问题之前 alert，比如说 log space 超过一个 threshold 就发出警告

一共有三种 metrics: counter, gauge (current value), histogram (how large/ long)

对比起 aws cloudwatch 的 push 机制（集中管理的monitor），prometheus 使用的是 pull system，减少了 infra 内部的压力，更好地检测 service 是否正在运行

# Grafana

是一个前端，用于展示 jenkins CI/CD 等数据：log 和 matrics