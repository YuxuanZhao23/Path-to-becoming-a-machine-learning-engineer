# 综述

## 转化流程

$$曝光\text{ impression: }推荐系统让你看到了这篇笔记$$
$$\downarrow$$
$$点击\text{ click }（停留了几秒：有效点击）$$
$$\downarrow$$
$$滑动到底\text{ scroll to end }/点赞\text{ like }/收藏\text{ collect, save }/转发\text{ forward, share }/评论\text{ comment }$$

## 消费指标

这里说的都是对于某一篇笔记来说

点击率 CTR = $\frac{\text{点击次数}}{\text{曝光次数}}$

点赞率 = $\frac{\text{点赞次数}}{\text{点击次数}}$

收藏率 = $\frac{\text{收藏次数}}{\text{点击次数}}$

转发率 = $\frac{\text{转发次数}}{\text{点击次数}}$

阅读完成率 = $\frac{\text{滑动到底次数} \times f(\text{笔记长度})}{点击次数}$, f() 这里做的是归一化的事情，使得长笔记的完成率有补偿

只关注这些短期指标会竭泽而渔，长期来看要增加用户粘性和活跃度需要多样性

## 北极星指标

- 用户规模：日活用户数 DAU，月活用户数 MAU
- 消费：人均使用的时长，阅读笔记的数量
- 发布：渗透率，人均发布量

## 实验流程

$$离线实验：收集历史数据，在上面做训练和测试（回测），没有用户的交互（到底怎么判断模型的好坏）$$
$$\downarrow$$
$$小流量\text{AB测试}：线上实验得到北极星指标$$
$$\downarrow$$
$$全流量上线（推全）$$

# 链路

$$\downarrow 亿$$
$$召回（有几十条通道，每条通道会取回几十～几百篇笔记）$$
$$\downarrow 千$$
$$粗排（轻量级的模型来打分，按排序来截断，保留分数最高的几百篇）$$
$$\downarrow 百$$
$$精排（大型神经网络，使用更多特征，计算量更大，小红书不做截断）$$
$$\downarrow 百$$
$$重排（按多样性抽样，相似内容打散，插入广告/运营内容）$$
$$\downarrow 十$$

## 召回通道

通道一般是常见的：协同过滤，双塔模型，关注的作者

之后会做去重和过滤（去掉用户不喜欢的话题/内容/作者）

## 粗排/精排

粗排使用规则保证筛选到的笔记具有多样性

$$用户特征 + 物品特征 + 统计特征$$
$$\downarrow$$
$$神经网络$$
$$\downarrow$$
$$预估值：点击率，点赞率，收藏率，转发率$$
$$比如 \downarrow 加权求和$$
$$排序分数$$

这里只是一个模型的结果，实践中需要再融合多个类似模型的分数

## 重排

- 多样性抽样，比如说 MMR 或者 DPP，从几百篇选出几十篇
- 用规则打散笔记：比如说第一个内容是 NBA，那么附近就不能有 NBA 的内容
- 插入广告，运营推广内容，根据生态要求调整排序（不能连着出美女内容）
- 有最多的代码：好几千行，业务代码

# A/B 测试

1. 新的 GNN 召回通道的离线实验结果很好
2. 线上小流量 A/B 测试（10%），考察线上指标，选择最优的超参数（比如说 GNN 的深度取值 $\in \{1, 2, 3\}$）

## 随机分桶

按10%用户而不是流量10%

hash user id 成某个区间的整数，然后把这些整数均匀随机分成 10 个桶

我们可以让 1 号桶对应一个超参数，2号桶对应另一个，3号桶做对照组

计算每个桶的业务指标，比如说 DAU，人均使用时长，CTR 等等，如果显著优于对照组，那么说明策略有效，值得推全

## 分层实验

层：召回，粗排，精排，重拍，用户界面，广告

同一层互斥：
- 比如说 GNN 用了其中4个桶，那么其他实验只能用剩余的6个桶
- 策略可能是天然互斥的，用户只能使用其中一种
- 两条不同的召回通道可能会有相互增强/抵消的影响

不同层正交：
- 每一层独立随机对用户做分桶，每一层都可以使用100%的用户来做实验（有参考文献 Overlapping experiment infrastructure: more, better, faster experimentation：https://dl.acm.org/doi/abs/10.1145/1835804.1835810）
- 假设：不同层的实验之间通常不容易相互增强或抵消

## Holdout 机制

如何考察个人和部门对于业务指标的提升？

- 取出 10% 的用户作为 holdout 桶，推荐系统只使用剩余的 90% 用户做实验，两者互斥（用户界面可以仍可以使用 100% 用户做实验，因为是正交的）
- 最后计算 10% holdout 和 90% 实验桶的差别（需要归一化），就是整个推荐部门的业务指标收益
- 考核周期结束的时候清除 holdout 桶，推全所有 100% 用户。然后重新随机划分 holdout 桶

## 推全

新建一个推全层（90%用户），这个层与其他层正交。新的召回实验会使用这一层作为 baseline吗？应该是的

## 反转实验

- 在新的推全层上，保留一个小反转桶使用旧的策略，长期观测新旧策略的区别
- 这个反转桶不会受到考核结束推全 100% 用户的影响，会长期保留
- 点击，交互会很快受到新策略的影响，但是长期留存指标有滞后性
- 有显著受益应当尽快推全，腾出桶提供给其他实验
- 反转实验是解决这个长短期的矛盾

# retrieval 召回算法

## ItemCF 召回

Item Collaborative Filtering

$$
\left.
\begin{array}{c}
我喜欢看《笑傲江湖》\\
《笑傲江湖》和《鹿鼎记》相似\\
我没看过《鹿鼎记》
\end{array}
\right \}
\rightarrow 推荐鹿鼎记
$$

1 和 3 可以通过历史记录得知，算法解决的是 2

- 知识图谱：作者相同所以相似
- 用户行为：看过《笑傲江湖》的人也看过《鹿鼎记》，好评《笑傲江湖》的人也好评《鹿鼎记》

$$
用户 u
- 兴趣 \text{ like}(u, i_j) \rightarrow
\left\{
\begin{aligned}
物品 i_1 \\
物品 i_2 \\
物品 i_3
\end{aligned}
\right\}
\leftarrow
相似度 \text{ sim}(i_j, i)
\rightarrow
候选物品 i
$$

- 用户对交互过的物品兴趣的分数：根据互动的多少来打分 (fixed rules)
- 预估用户对候选物品的兴趣：$\displaystyle \sum_{j}\text{like(user, }item_j\text{)} \times \text{sim(}item_j\text{, item)}$

### 物品相似度

两个物品的受众重合度越高，两个物品就越相似

喜欢物品 $i_1$ 的用户记作集合 $W_1$，喜欢物品 $i_2$ 的用户记作集合 $W_2$，如果这两个用户群体大小相差很大呢

$$\text{sim(}i_1, i_2\text{)} = \frac{|W_1 \cap W_2|}{\sqrt{|W_1||W_2|}} \in [0, 1]$$

这个公式不涉及用户喜欢的程度，是 binary，下面这个余弦相似度公式使用了 like()：把每一个物品表示成一个稀疏向量，向量每一个元素对应一个用户，相似度就是两个向量夹角的余弦

$$\text{sim(}i_1, i_2\text{)} = \frac{\displaystyle\sum_{v \in W_1 \cap W_2}like(v, i_1) like(v, i_2)}{\sqrt{\displaystyle\sum_{u_1 \in W_1}like(u_1, i_1)^2} \sqrt{\displaystyle\sum_{u_2 \in W_2}like(u_2, i_2)^2}} \in (0, 1)$$

### 离线计算

为了能够及时 serve，需要事先做离线计算

用户 $\rightarrow$ 物品的索引：
- 每个用户的最近点击交互过的物品 id（比如说200个）以及分数
- user 2: [(item 3, 5), (item 7, 2), ...]

物品 $\rightarrow$ 物品的索引：
- 给定任意物品 id，可以快速找到最相似的 k 个物品以及相似度分数
- item 7: [(item 1, 0.7), (item 2, 0.6), ...]

为什么用索引？
- 离线计算量大，线上计算量小（避免枚举所有物品）
- 打分只需要给最多 nk 个物品打（比如说 100 * 20）

### 线上召回

1. 给定用户 id，通过用户 $\rightarrow$ 物品索引找到 last-n
2. 给 last-n 里每个物品通过物品 $\rightarrow$ 物品索引找到 top-k
3. 对这最多 nk 个物品计算预估的用户兴趣分数，截取前100个

## Swing 召回

解决 itemCF 的一个问题：如果重合的人是一个小圈子，比如说这两篇笔记被分享到微信群里了，那么 itemCF 计算出来的重合度高就不对了，其实这两篇笔记没什么相似的地方

itemCF 成立的前提是重合的人需要是大量的、不相关的人

定义两个用户的重合度：$\text{overlap}(u_1, u_2) = |J_1 \cap J_2|$, $J_i$ 是用户 $u_i$ 喜欢的物品集合

### 物品相似度

swing 模型计算相似度：$\text{sim(}i_1, i_2\text{)} = \displaystyle\sum_{u_1\in W_1 \cap W_2}\displaystyle\sum_{u_2\in W_1 \cap W_2}\frac{1}{\alpha + \text{overlap}(u_1, u_2)}$, 集合 $W_j$ 是喜欢物品 $i_j$ 的人的集合

$\alpha$ 是一个可以调节的超参数，如果某两个人 $u_1, u_2$ 同时喜欢物品 $i_1, i_2$，但是他们两个的重合度很高，那么分母变大，权重降低

## UserCF 召回

$$
\left.
\begin{array}{c}
有很多网友和我兴趣非常相似\\
其中一个网友对某一篇笔记点赞、转发\\
我没看过这篇笔记
\end{array}
\right \}
\rightarrow 推荐这篇笔记
$$

如何找到兴趣非常相似的网友呢？
- 交互的笔记有很大的重合
- 关注的作者有很大的重合

$$
用户 u
\leftarrow 相似度 \text{ sim}(u, u_j) \rightarrow
\left\{
\begin{aligned}
用户 u_1 \\
用户 u_2 \\
用户 u_3
\end{aligned}
\right\}
- 兴趣 \text{ like}(u_j, i)
\rightarrow
候选物品 i
$$

预估用户对预选物品的兴趣：$\displaystyle \sum_{j}\text{sim}(u, u_j) \times \text{like}(u_j, i)$

### 用户相似度

用户相似度：$\text{sim}(u_1, u_2) = \frac{|J_1 \cap J_2|}{\sqrt{|J_1||J_2|}} = \frac{\displaystyle\sum_{l \in |J_1 \cap J_2|}1}{\sqrt{|J_1||J_2|}} \in (0, 1)$, $J_i$ 是用户 $u_i$ 喜欢的物品集合

把用户表示为一个稀疏向量，每个元素对应一个物品，相似度sim()就是两个向量夹角的余弦

越热门的物品，对计算相似度就越没有用，重合的东西越冷门越能反映两个人的兴趣真的很相似，改写用户类似度为：$\text{sim}(u_1, u_2) = \frac{\displaystyle\sum_{l \in |J_1 \cap J_2|}\frac{1}{log(1 + n_l)}}{\sqrt{|J_1||J_2|}} \in (0, 1)$, $n_l$ 是喜欢物品l的用户数量，反映了物品的热门程度

### 离线计算

- 需要一个和 itemCF 相同的用户 $\rightarrow$ 物品的索引
- 需要一个用户 $\rightarrow$ 用户的索引
- user 7: [(user 1, 0.7), (user 2, 0.6), ...]

### 线上召回

1. 给定用户 id，通过用户 $\rightarrow$ 用户索引找到 top-k
2. 给 top-k 里每个用户通过用户 $\rightarrow$ 物品索引找到 last-n
3. 对这最多 nk 个物品计算预估的用户兴趣分数，截取前100个

## 向量召回

### 离散特征处理

1. 建立字典：把类别映射成序号
2. 向量化：one-hot 高维稀疏向量（类别很少的时候），embedding 低维稠密向量

embedding

- 输入：数字序号
- 输出：向量，是矩阵里的一列，在 tf 和 torch 里面有 embedding 层，训练神经网络的时候会自动反向传播学习这些参数
- 参数是矩阵形式的向量维度 $\times$ 类别（假设国籍embedding是四维的，200个国籍，那么就是 4 $\times$ 200 = 800）
- 维度一般很小，但是类别却可以非常大（航天里有几十亿），很多模型的绝大多数参数都在 embedding 层，工业界会对 embedding 层做很多优化，是存储和计算的关键所在
- embedding 层到底学了什么？训练好了的话，逻辑/语义上相似的类别的相对距离会很近
- embedding 和 one-hot 的关系：参数矩阵 $\times$ one-hot 就会得到 embedding，因为相当于把对应类别的那一列取了出来

### 矩阵补充 Matrix Completion

矩阵补充的名字由来：我们可以有这样一个矩阵（物品 $\times$ 用户），已曝光的位置我们有真实的兴趣分数，我们用预测值去填写还没曝光的位置

对于 user id 和 item id 各自做 embedding，然后内积得到一个数字。这两个 embedding 的参数是不共享的

ML目标：内积 $<a_u, b_i>$ 拟合真实观测的兴趣分数，优化 $\displaystyle \min\limits_{A, B} \displaystyle\sum_{(u, i, y) \in \Omega}(y - <a_u, b_i>)^2$

数据集：$\Omega = \{(\text{用户 id }u, \text{物品 id }i, \text{兴趣分数 }y)\}$

兴趣分数：
- 曝光了没有点击：0
- 点击，点赞，收藏，转发：各1
- 范围 [0, 4]

实践中表现不好
- 只用了 ID embedding，没有使用物品和用户的属性，可以将双塔理解成矩阵补充的升级
- 负样本选取了曝光后没有点击+交互：错误的做法
- 训练的方法不好：内积不如余弦相似度，平方损失（回归）不如 cross entropy loss（分类）

模型存储
- A 每一列是一个用户，B 每一列是一个物品
- A 可以存储成一个 key-value 表: id-embedding
- B 很复杂

线上服务
1. 查询 key-value 表得到用户向量 $a$
2. 最近邻查找 nearest neighbor search：用户最有可能感兴趣的k个物品（内积 $<a, b_i>$ 最大的 k 个物品），枚举所有的物品的时间复杂度和物品数量成正比，难以接受

近似最近邻查找 approximate nearest neighbor search：
- 很多系统都支持：Milvus, Faiss, Hnswlib
- 最近邻的标准：L2 距离最小，向量内积最大，向量夹角余弦最大（夹角最小， 等同于归一化的向量内积）
- 如果是余弦的标准，那么我们可以划分扇区，然后一个平均的归一向量代表一个扇区。query只需要和这些归一向量（万级）做余弦，然后和最大的一个所属于的扇区里的所有点做余弦得到结果（万级），这样就能把亿级的运算减少到万级

### 双塔模型

注意神经网络是两个，分别对应用户和物品，我们计算结果使用的是两个神经网络输出的结果（后期融合）。如果我们把用户和物品直接 concatenate 在一起输入一个神经网络来做召回（前期融合）是不合适的，因为如果有一亿个物品，做召回的时候运行神经网络一亿次是显然不可行的。前期融合的模型可以做排序。

那为什么后期融合的双塔模型可以，因为用户和物品的表征向量都可以进行事先准备，而且计算余弦最近邻是有近似方法可以降低到万级的。

$$
\left.
\begin{array}{c}
\left.
\begin{array}{c c c}
用户\text{id} &\rightarrow& \text{embedding layer}\\
用户离散特征 &\rightarrow& \text{embedding layer}\\
用户连续特征 &\rightarrow& 归一化/分桶/取对数
\end{array}
\right \}
concatenate
\rightarrow 神经网络 \rightarrow 用户的表征向量\\
\\
\left.
\begin{array}{c c c}
物品\text{id} &\rightarrow& \text{embedding layer}\\
物品离散特征 &\rightarrow& \text{embedding layer}\\
物品连续特征 &\rightarrow& 归一化/分桶/取对数
\end{array}
\right \}
concatenate
\rightarrow 神经网络 \rightarrow 物品的表征向量
\end{array}
\right \}
余弦相似度
$$

$$cos(a, b) = \frac{<a, b>}{\sqrt{\displaystyle\sum_{a_i \in a} a_i^2} \sqrt{\displaystyle\sum_{b_i \in b} b_i^2}} \in [-1, 1]$$

训练方式：
- pointwise：独立看待，简单二元分类
- pairwise：每次取一个正样本，一个负样本（Facebook）
- listwise：每次取一个正样本，多个负样本（YouTube）

#### pointwise 训练

- 把召回看成二元分类任务
- 正样本鼓励cos(a, b)接近+1，负样本鼓励cos(a, b)接近-1
- 正负样本 1:2 或者 1:3

#### pairwise 训练

$$
\left.
\begin{array}{c c c c c c c }
物品正样本\text{ id} &\rightarrow &特征变换t_i &\rightarrow &神经网络n_i &\rightarrow &b^+\\
用户 &\rightarrow &特征变换t_u &\rightarrow &神经网络n_u &\rightarrow &a\\
物品负样本 &\rightarrow &特征变换t_i &\rightarrow &神经网络n_i &\rightarrow &b^-
\end{array}
\right \} 
\rightarrow
\begin{array}{c}
cos(a, b^+)\\
cos(a, b^-)
\end{array}
$$

想法是鼓励 $cos(a, b^+)$ 大于 $cos(a, b^-)$，我们设置一个超参数 m 使得 $cos(a, b^+) \geq cos(a, b^-) + m$ 的时候没有损失，否则损失等于 $cos(a, b^-) + m - cos(a, b^+)$

Triplet hinge loss: $L(a, b^+, b^-) = \max\{0, \cos(a, b^-) + m - cos(a, b^+)\}$

Triplet logistic loss: $L(a, b^+, b^-) = log(1 + e^{\sigma(\cos(a, b^-)- cos(a, b^+))})$, $\sigma$ 是控制损失函数形状的超参数

#### listwise 训练

$$
\left.
\begin{array}{c c c c c }
cos(a, b^+) &\rightarrow &\text{softmax} &\rightarrow &s^+\\
cos(a, b^-_1) &\rightarrow &\text{softmax} &\rightarrow &s^-_1\\
... cos(a, b^-_n) &\rightarrow &\text{softmax} &\rightarrow &s^-_n
\end{array}
\right \} 
\rightarrow
\text{crossEntropyLoss}([1, 0, ...], s) = -log(s^+)
$$

batch 内负样本 + listwise

损失函数 $L_{\text{main}}[i] = -\log\frac{e^{\cos(a, b^+)}}{e^{\cos(a, b^+)} + e^{\cos(a, b^-_1)} + ... + e^{\cos(a, b^-_n)}}$，其中 $s^+ = \frac{e^{\cos(a, b^+)}}{e^{\cos(a, b^+)} + e^{\cos(a, b^-_1)} + ... + e^{\cos(a, b^-_n)}}$

梯度下降，减小损失函数 $\frac{1}{n}\displaystyle\sum_{i=1}^n L_{\text{main}}[i]$，n 是所有的用户

#### 线上服务

- 保存物品的 <特征向量，物品id> 到向量数据库(Milvus, Faiss, Hnswlib)，几亿个物品向量现算的成本很高
- 用户的特征向量a需要在发起请求的时候才计算。然后用a作query在向量数据库最近邻查找 top-k，为什么不事先算好用户的向量呢？因为用户的兴趣是会变化的（推荐的效果不好），但是物品的特征相对稳定

#### 模型更新

全量更新：凌晨用昨天的全天数据随机打乱训练 1 epoch
- 在昨天的模型参数基础上训练（不是在增量模型上），不是随机初始化
- 发布新的用户塔和神经网络和物品向量
- 对数据流和系统的要求比较低
- 更新之后就抛弃昨天增量更新出来的 embedding 了（有新的 embedding 了）

增量更新：online learning 更新模型参数
- 用户兴趣随时发生变化
- 实时收集线上数据，做流式处理，生成 TFRecord
- 在上一次增量更新的基础上只更新用户的 id embedding 的参数，锁住神经网络的其他部分
- 发布用户的 embedding，供用户塔在线上计算用户向量

可以只做增量更新吗？
- 不可以，小时/分钟级的数据偏差很大，增量训练是按照时间顺序来训练的
- 全量更新 shuffle 一天的数据可以减少 bias

#### 自监督学习

解决头部效应，长尾物品的表征学的不好。自监督学习做的是 data augmentation，能更好的学习长尾物品的向量表征

自监督学习使用了不同的变换，让同一个物品可以有不同的特征值输入物品塔，目标是同一个物品得到的embedding要很相似（$\cos(b'_i, b''_i)$尽量大），不同的物品的embedding要很不相似（$\cos(b'_i, b''_j)$尽量小）

那都有哪些常见的特征变换呢？
- Random Mask：随机遮住某一个离散特征 {美妆，摄影} $\rightarrow$ {默认}
- Dropout：一个物品有多个类目，随机丢弃掉50%的值 {美妆，摄影} $\rightarrow$ {美妆}
- complementary：{ID，类⽬，关键词，城市} $\rightarrow$ {ID，关键词} 和 {类⽬，城市}
- Mask related feature：
  - 离线计算特征两两之间的关联: mutual information $MI(U, V) = \displaystyle\sum_{u \in U}\displaystyle\sum_{v \in V} p(u, v) \log \frac{p(u, v)}{p(u)p(v)}$
  - 假设有k个特征，那么就有 $k \times k$ 的MI矩阵
  - 随机选择一个特征作为种子，mask 与之相关的 $\frac{k}{2}$ 种特征
  - 效果最好，方法复杂，不容易维护

训练模型的损失函数 $L_{\text{self}}[i] = -\log\frac{e^{\cos(b'_i, b''_i)}}{\displaystyle\sum_{j=1}^m e^{\cos(b'_i, b''_j)}}$

梯度下降，减小损失函数 $\frac{1}{n}\displaystyle\sum_{i=1}^m L_{\text{self}}[i]$，m 是所有的物品

#### 训练模型

- 对点击做随机抽样（热门物品会比较多：打压），得到 n 对用户-物品二元组作为一个 batch
- 对全体物品均匀抽样（冷门物品比较多：更好表达长尾物品的向量表征），得到 m 个物品作为一个 batch
- 梯度下降：$\frac{1}{n}\displaystyle\sum_{i=1}^n L_{\text{main}}[i] + \alpha \frac{1}{n}\displaystyle\sum_{j=1}^m L_{\text{self}}[j]$

### 选择样本

#### 正样本

- 曝光而且有点击的用户-物品二元组
- 问题是28法则，少部分的物品占据了大部分的点击
- up-sampling 多次出现冷门物品，downsampling 概率抛弃热门物品

#### 负样本

简单负样本
- 未被召回的样本：绝大多数的物品 $\approx$ 全体物品，所以直接在所有物品里随机抽样
  - 均匀抽样：对冷门物品不公平，因为这样的话基本上所有的负样本都是冷门物品
  - 非均匀抽样：
    - 打压热门物品，越热门越容易被抽样成为负样本
    - $抽样概率 \propto 点击次数^{0.75}$
    - 0.75 是经验值
- batch 内负样本：
  - 用户a和被用户b点击了的物品c组成的<a, c>是一个负样本，问题是热门物品的抽样概率 $\propto$ 点击次数，这样概率就过大了
  - 解决方法：训练的时候用户对于物品i的兴趣为 $\cos(a, b_i) - \log(p_i)$，召回的时候仍然使用 $\cos(a, b_i)$，$p_i \propto$ 点击次数（抽正常抽，但是热门的物品不会修正太多）

困难负样本
- 被粗排淘汰的物品（比较困难），被精排淘汰的物品（非常困难）
- 二元分类很难分

我们可以用 50% 的全体物品（简单负样本） + 50% 没通过排序的物品（困难负样本）来做训练数据。

可以用曝光了没有点击作负样本吗？
- 不可以，这种不是对于召回的负样本，是排序的负样本。
- 为什么？因为召回的目标是找到感兴趣的物品，而不是感兴趣的物品中找到非常感兴趣的
- 可能只是碰巧没点击，不代表不感兴趣，用户不可能点击每一个物品

## Deep Retrieval

把物品表征为 path，线上查找用户最匹配的路径，是tiktok的实现方式，也类似于阿里的TDM

路径 $\leftrightarrow$ [物品, ...]

物品 $\leftrightarrow$ [路径, ...]

线上召回：用户 $\rightarrow$ 一批路径 $\rightarrow$ 一批物品（排序）

路径的深度 d 如果很大的话，探索所有的路径可能就是 $K^d$，使用 beam search 来改善这一点。如果 beam = 1 的时候我们其实就是贪心算法，每次只选 local optimal，beam b 是我们探索 top-b 个的意思

物品和路径的相关性 $\text{score(item, path) = }\displaystyle\sum_{user}\text{p(path|user)} \times \text{click(user, item)}$

损失函数：选择和 item 高度相关的路径 $loss(item, \prod) = -log(\displaystyle\sum_{j = 1}^J\text{score(item, }path_j))$

正则项：避免过多的物品在同一条 path 上 $reg(path_j) = (\text{number of items on }path_j)^4$

更新路径：在从未被选中的路径中选出一条 $path_l \leftarrow argmin_{path_l}loss(item, \prod) + \alpha \text{ reg}(path_l)$，选中的路径 score 高，同时路径上的物品数量不多

## 其他召回通道（实用，不那么重要）

GeoHash 召回：
- 用户可能对附近发生的事情感兴趣
- GeoHash 是地图上的一个长方形区域
- 索引：GeoHash $\rightarrow$ 按时间倒排的**优质**笔记列表
- 这条通道没有个性化

同城召回：
- 用城市/曾经生活过的城市

作者召回：
- 用户对关注的作者的笔记感兴趣
- 召回：用户 $\rightarrow$ 关注的作者 $\rightarrow$ 最新的笔记

有交互的作者召回：
- 如果用户对某一篇笔记感兴趣（点赞，收藏，转发），那么用户可能对该作者的其他笔记感兴趣
- 召回：用户 $\rightarrow$ 有交互的作者 $\rightarrow$ 最新的笔记

相似作者召回：
- 索引：作者 $\rightarrow$ 相似作者
- 召回：用户 $\rightarrow$ 感兴趣的作者 $\rightarrow$ 相似作者 $\rightarrow$ 最新的笔记

缓存召回：
- 复用之前 n 次推荐精排的结果
- 精排有一大半没有曝光，被浪费，值得再次尝试
- 精排前50没有曝光，缓存起来，作为一条召回通道
- 缓存大小固定，需要退场机制：笔记曝光，最老的，最多召回10次，最多保存3天

## 曝光过滤

用户看过这个物品就不再把这个物品曝光给该用户（召回之后对曝光物品做过滤），YouTube 的算法会曝光同一个

小红书只召回一个月以内的笔记，那么用户就需要记录最近一个月的曝光历史

一个用户看过 n 个物品（千），召回 r 个物品（千），暴力对比需要 $O(nr)$ 的时间

实践中使用 bloom filter，如果判断是 no 那就一定不在集合中，yes 则可能在集合中（错误过滤未曝光的物品）
- 将物品集合表征为一个 m 维二进制向量
- bloom filter 有 k 个哈希函数，每个哈希函数将 id 映射成 0～m-1的整数
- query的时候有一个位置为0就说明没有曝光
- 错误判断的概率 $\delta \approx (1 - e ^ {-\frac{kn}{m}})^k$ m 越大越不容易冲突，n 越大越容易判错，k太大太小都不好
- 如果可以忍受的错误判断概率是 $\delta$，那么最优参数是 $k = 1.44 \ln(\frac{1}{\delta})$, $m = 2n \ln(\frac{1}{\delta})$
- 在前端有埋点，一旦曝光就会立刻用实时流进行处理（Kafka 队列 + Flink 实时计算哈希值），然后尽快写进 bloom filter，因为两次刷新的间隔可能只有几分钟，所以bloom filter的更新一定要及时
- 缺点：只能添加，不能删除（因为是共享的，不能改成0），只能从头算一遍

# 排序

排序模型预估的是点击率，点赞率，收藏率，转发率等分数，然后做融合（比如说加权和），最后排序截断

## 多目标模型

$$
\left.
\begin{array}{c}
用户特征\\
物品特征\\
统计特征\\
场景特征
\end{array}
\right \}
\rightarrow 
\left.
\begin{array}{c}
神经网络\\
\text{shared bottom}
\end{array}
\right.
 \rightarrow
\left \{
\begin{array}{c}
全连接层 + \text{Sigmoid} \rightarrow 点击率\\
全连接层 + \text{Sigmoid} \rightarrow 点赞率\\
全连接层 + \text{Sigmoid} \rightarrow 收藏率\\
全连接层 + \text{Sigmoid} \rightarrow 转发率
\end{array}
\right.
$$

损失函数 $\displaystyle\sum_{i=1}^4 \alpha_i \text{CrossEntropy}(y_i, p_i)$，$y_i$ 是目标值，$p_i$ 是预估值

训练
- 正负样本差异悬殊：负样本降采样
- 预估值校准：因为负样本变少，所以预估值大于真实值，假设我们使用了 $\alpha n_-, \alpha \in (0, 1)$
  - 真实点击率：$p_{true} = \frac{n_+}{n_+ + n_-}$
  - 预估点击率：$p_{pred} = \frac{n_+}{n_+ + \alpha n_-}$
  - 联立上面两个公式得到：$p_{true} = \frac{\alpha p_{pred}}{(1 - p_{pred}) + \alpha p_{pred}}$

## Multi-gate Mixture of Experts (MMoE)

MMoE 不一定会有提升，有可能是算法写的不好，也可能是场景不适合 MMoE

$$
\left.
\begin{array}{c}
用户特征\\
物品特征\\
统计特征\\
场景特征
\end{array}
\right \}
concatenate \rightarrow
\left \{
\begin{array}{c}
专家神经网络1 \rightarrow 向量\vec{x_1}\\
专家神经网络2 \rightarrow 向量\vec{x_2}\\
专家神经网络3 \rightarrow 向量\vec{x_3}\\
专家神经网络4 \rightarrow 向量\vec{x_4}\\
神经网络1 \rightarrow \text{softmax} \rightarrow 权重[p_1, p_2, p_3, p_4]\\
神经网络2 \rightarrow \text{softmax} \rightarrow 权重[q_1, q_2, q_3, q_4]\\
...
\end{array}
\right \}
\left.
\begin{array}{c}
\displaystyle\sum_{i=1}^4 p_i\vec{x_i} \rightarrow 神经网络 \rightarrow 点击率\\
\displaystyle\sum_{i=1}^4 q_i\vec{x_i} \rightarrow 神经网络 \rightarrow 点赞率\\
...
\end{array}
\right.
$$

通常专家网络是4个或者8个，这是一个超参数，可以调

### Polarization 极化现象

softmax 激活函数给出的权重只有一个接近1，其余都接近0，这样就只用到一个专家，没用到专家融合的优势

训练的时候对 softmax 的输出使用 dropout

- softmax 输出的 n 个数值被 mask 的概率是 10%
- 每个专家被随机 dropout 的概率都是 10%

## 预估分数融合

简单加权和：$p_{click} + w_1 p_{like} + w_2 p_{collect} + ...$

点击率乘以其他项的加权和：$p_{click} (1 + w_1 p_{like} + w_2 p_{collect} + ...)$

Tiktok 的分数融合：$(1 + w_1 p_{time})^{\alpha_1}  (1 + w_2 p_{like})^{\alpha_2} ...$

快手的分数融合：
1. 预估时长，点击，点赞，转发，评论并排序得到排名 $r_{time}, r_{click}, r_{like}, ...$
2. 融合分数：$\frac{w_1}{r_{time}^{\alpha_1} + \beta_1} + \frac{w_2}{r_{click}^{\alpha_2} + \beta_2} + ...$

京东的分数融合：$p_{click}^{\alpha_1} \times p_{cart}^{\alpha_2} \times p_{pay}^{\alpha_3} \times price^{\alpha_4}$，假如说所有的参数 $\alpha$ 都是 1 得到的就是营收，有很强的物理意义

## 视频指标

视频排序的依据主要是播放时长和完播率，图文笔记的点击，点赞，收藏，转发，评论都不那么重要了

### 播放时长

直接用 regression 来拟合播放时长的效果不好，所以我们预测的是相对值

$$
\left.
\begin{array}{c}
用户特征\\
视频特征\\
统计特征\\
场景特征
\end{array}
\right \}
\rightarrow 神经网络 \rightarrow
\left \{
\begin{array}{c}
全连接层 \rightarrow ...\\
全连接层 \rightarrow ...\\
全连接层 \rightarrow ...\\
全连接层 \rightarrow z
\end{array}
\right.
$$

- 定义一个 $y = \frac{t}{1+t}, p = \frac{e^z}{1 + e^z}$
- 用 cross entropy $CE(y, p) = y \log(p) + (1-y)\log(1-p) = \frac{t}{1 + t}\log p + \frac{1}{1 + t}\log (1-p)$ 来优化，实际上我们只需要最小化 $-(t \log p + \log(1-p))$（这里的符号？）
- 预测的时候使用 $e^z$ 当作预测的时长

### 完播

- 回归：用 p 拟合实际播放率 y： $loss = y \log p + (1-y) \log(1-p)$
- 二元分类：定义完播的指标，比如看完 80%，预测值是 $P(play > 80\%)$，融分公式不能直接用，需要一个函数 f 来拟合播放时长和完播率，使用 $p_{finish} = \frac{预估完播率}{f(视频长度)}$，这样调整之后对于长视频才公平

## feature 特征

### 用户画像 User Profile

- 用户 id（在召回，排序中做embedding）
- 人口统计学：性别，年龄
- 账号信息：新老，活跃度
- 感兴趣的：类目，关键词，品牌

### 物品画像 Item Profile

- 物品 id（在召回，排序中做embedding）
- 发布时间/年龄
- GeoHash，所在城市
- 标题，类目，关键词，品牌
- 字数，图片数，视频清晰度，标签数
- AI给内容信息量，图片美学的打分

### 用户统计特征

- 用户最近30天(7天、1天、1小时)的曝光数、点击数、点赞数、收藏数
- 照笔记图文/视频分桶（比如最近7天，该用户对图文笔记的点击率、对视频笔记的点击率）
- 按照笔记类目分桶（比如最近30天，用户对美妆笔记的点击率、对美食笔记的点击率、对科技数码笔记的点击率）

### 笔记统计特征

- 笔记最近30天(7天、1天、1小时)的曝光数、点击数、点赞数、收藏数
- 按照用户性别分桶、按照用户年龄分桶
- 作者特征
  - 发布笔记数
  - 粉丝数
  - 消费指标(曝光数、点击数、点赞数、收藏数)

### 场景特征

- GeoHash，城市
- 当前时刻（分桶，做embedding）
- 周末/节假日
- 手机品牌，手机型号，操作系统

### 特征处理

- 离散特征：embedding
  - 用户 id，笔记 id，作者 id
  - 类目，关键词，城市，手机品牌
- 连续特征
  - 分桶，变成离散特征：年龄，笔记字数，视频长度
  - 变换
    - 曝光数，点击数，点赞数做 $\log(1 + x)$
    - 转化为点击率，点赞率，再做平滑（去掉极端值）

### 特征覆盖率

很多特征不能覆盖 100% 样本，比如说年龄和地理定位，要想办法多收集特征，以及缺失特征的时候默认值放什么

### 数据服务

$$用户请求\downarrow $$

$$召回服务器 \leftrightarrow 主服务器$$

$$（多样性/分数融合/规则后）排序好的内容 \uparrow \downarrow 物品id，用户id，场景特征$$

$$
排序服务器
\leftarrow
\left \{
\begin{array}{ c c c }
用户特征& \leftarrow& 用户画像（较为静态）\\
物品特征& \leftarrow& 物品画像（静态）\\
统计特征& \leftarrow& 统计数据（动态）
\end{array}
\right.
$$

$$排序分数 \uparrow \downarrow 特征打包$$

$$\text{TF serving}$$

## 粗排

介于双塔这种后期融合和多目标模型这种前期融合的方法：主要是筛选而不是排序

$$
\left.
\begin{array}{ c c c }
用户+场景特征& \rightarrow& 用户塔（很大）\\
物品特征（静态）& \rightarrow& 物品塔（较大）\\
统计+交叉特征& \rightarrow& 交叉塔（较小）
\end{array}
\right \}
\rightarrow
\left.
\begin{array}{ c }
\text{concatenate}\\
\text{cross}
\end{array}
\right.
\rightarrow
\left \{
\begin{array}{c}
全连接层 + \text{Sigmoid} \rightarrow 点击率\\
全连接层 + \text{Sigmoid} \rightarrow 点赞率\\
全连接层 + \text{Sigmoid} \rightarrow 收藏率\\
全连接层 + \text{Sigmoid} \rightarrow 转发率
\end{array}
\right.
$$

- 用户塔：只有一个用户，只做一次推理，就算塔很大计算量也不大
- 物品塔：理论上需要n次推理，但是绝大多数时候使用缓存值，因为只给新物品计算
- 交叉塔：n个物品就需要做n次推理，所以必须做的比较小
- 上层的全连接层必须做n次推理，给n个物品打分，大部分计算量都在这里

# 特征交叉

在召回和排序中都会用到

## Factorized Machine

线性模型 $p = b + \displaystyle\sum_{i=1}^d w_i x_i$

二阶交叉特征 $p = b + \displaystyle\sum_{i=1}^d w_i x_i + \displaystyle\sum_{i=1}^d\displaystyle\sum_{j=i+1}^d u_{ij} x_i x_j$

这里的矩阵 U 我们可以想办法找到一个 $k \times d$ 的矩阵相乘来模拟

$p = b + \displaystyle\sum_{i=1}^d w_i x_i + \displaystyle\sum_{i=1}^d\displaystyle\sum_{j=i+1}^d (v_i^T v_j) x_i x_j$

这个模型有 O(kd) 个参数，$k << d$，是线性模型的替代品，使用二阶交叉特征表现力会比线性模型更强，而且不同意过拟合。2010年的时候提出，当时算力匮乏，现在已经不常用

## 深度交叉网络 deep and cross network (DCN)

交叉层 $x_{i+1} = x_0 \circ (W x_i + b) + x_i$

全连接层之后与最初的输入$x_0$逐元素乘(Hadamard Product)，最后加上输入$x_i$（相当于ResNet的残差连接，防止梯度消失）

用于召回和排序中的“神经网络”

$$
\left.
\begin{array}{ c c c }
用户特征\\
物品特征\\
其他特征
\end{array}
\right \}
\rightarrow
\left \{
\begin{array}{c}
\text{FCN} \rightarrow 向量结果\\
\text{DCN} \rightarrow 向量结果
\end{array}
\right \}
\rightarrow
FCN
\rightarrow 向量结果
$$

## LHUC 网络结构

只能用于精排，起源于语音识别，快手用了之后叫做 PPNet

$$
\left.
\begin{array}{ c c c }
物品特征 \rightarrow FCN\\
用户特征 \rightarrow FCN + 2 * Sigmoid
\end{array}
\right \}
逐元素乘\rightarrow FCN
\left.
\begin{array}{ c c c }
向量结果\\
用户特征 \rightarrow FCN + 2 * Sigmoid
\end{array}
\right \}
逐元素乘
$$

为什么FCN之后要加一层sigmoid $\times 2$：因为主要是想默认值为1，同时保证均值和方差不变

## FiBiNet

可以放在精排，多放的这个bilinear和SENet会有收益

$$
\text{离散特征 embedding}
\rightarrow
\left \{
\begin{array}{ c c c }
concatenate\\
bilinear\\
SENet
\end{array}
\right \}
\text{和连续特征一起concatenate}
\rightarrow
上层网络
$$

### SENet

$m 个特征embedding \rightarrow \text{average pooling: m} \times 1 \rightarrow \text{FC + ReLU} 压缩成 \frac{m}{r} \times 1 \rightarrow \text{FC + sigmoid} 恢复成 m \times 1 \rightarrow \text{和开头的特征embedding做row-wise multiply}$

- 这里的 $m \times 1$ 的向量主要是给开头的特征向量加权，可以理解成 attention，或者说是对离散特征做 field-wise 加权
- embedding 的长度可以不同，因为做的是 average pooling

### Bilinear 双线性

- 内积：$f_{ij} = x_i^T x_j$
- 逐元素乘 Hadamard Product：$f_{ij} = x_i \circ x_j$
- Bilinear 内积：$f_{ij} = x_i^T W_{ij} x_j$ 有$\frac{m^2}{2}$个参数矩阵，不能给每一个都做交叉，会太大
- Bilinear Hadamard Product：$f_{ij} = x_i \circ (W_{ij} x_j)$ 会有 $m^2$ 个向量，同样不能给每一个都做交叉，会太大

# 行为序列（用户的 last-n）

在召回，粗排，精排的模型中，我们都需要把用户的 last-n 放在用户特征中：对每一个物品 id 做 embedding，然后 average pooling 得到一个向量

小红书的实践：

点击的 last-n 的 embedding（id和其他特征比如说类目） 做 average pooling

点赞的 last-n 的 embedding（id和其他特征比如说类目） 做 average pooling

评论的 last-n 的 embedding（id和其他特征比如说类目） 做 average pooling

收藏的 last-n 的 embedding（id和其他特征比如说类目） 做 average pooling

这样比只看所有的 last-n 和只看 id embedding 要好

## DIN 模型

- 用加权平均代替平均，本质是attention（单头注意力层，候选物品是query）
- 权重是候选物品和 last-n 物品的相似度（内积，相似度等等）
- 主要适用于精排模型，不能在双塔三塔中使用（因为用户塔看不见物品特征）

缺点：
- 注意力层的计算量 $\propto$ 用户行为序列的长度(n)
- 只能记录最近几百个物品，不然计算量太大
- 只关注短期兴趣，遗忘长期兴趣

## SIM 模型

- 可以保留几千的 last-n
- 对于每一个候选物品，在 last-n 中快速查找 k 个相似物品，然后输入到注意力层

### 查找

- hard search：根据候选物品的类目，只保留 last-n 物品中类目相同的
- soft search：embedding 向量的 k 最近邻查找，效果好，编程复杂，计算复杂，infra不好的话用 hard search 就可以了，速度比较快

### 注意力机制

trick：
- 要使用时间信息，记录用户与某一个 last-n 物品的交互时刻距今为 $\delta$
- 对 $\delta$ 做离散化（categorize），再做 embedding，变成向量 d
- concatenate d 和 $\delta$ 表征一个 last-n 物品
- 为什么 DIN 不用时间信息？因为 DIN 只用记录用户的近期行为

# 重排

我们想要 impression 有多样性，那么我们就需要度量相似性的方法：

- 基于物品属性标签
  - 一级类目，二级类目，品牌，关键词等，有不同的权重和
- 物品的向量表征
  - 并不是所有的 embedding 都适合，召回的双塔模型里的 embedding 就不适合（因为物品向量表征学不好新物品和长尾物品）
  - 最好是基于内容的向量表征：
    - CV: CNN + NLP: BERT 用公用的数据库效果不好，用小红书自己的数据还需要标注
    - CLIP：
      - 图片-文本 二元组，预测图文是否匹配，不需要人工标注，小红书大部分笔记天然包含图片和文字而且大部分时候图文相关
      - batch 内负样本，同一篇的是正样本，不同的是负样本

我们一般把精排的后处理叫做重排，事实上粗排也有后处理。类似的，粗排筛选出来的 top 几百并不是简单 threshold，而是需要兼顾分数和多样性

## Maximal Marginal Relevance (MMR)

原本是搜索的算法，现在也被用到推荐中

定义被选中的物品集合 S，未被选中的物品记作 R

$MR_i = \theta \cdot reward_i - (1 - \theta) \cdot \displaystyle\max_{j \in S} sim(i, j)$

$MMR = \displaystyle\argmax_{i \in R} MR_i$

```
初始化 S 为空集
未选中的物品 R 为全集
选择精排分数 reward 最高的物品从 R 移动到 S
循环 k-1 次：
    计算集合 R 中所有的物品分数 MR
    选出分数最高的物品，将其从 R 移动到 S
```

### 滑动窗口

已经选中的物品 S 越大，越难找到一个物品与 S 中的所有物品都不相似。也就是说在这个时候多样性分数总是约等于 1，MMR算法失效

解决方案：使用一个滑动窗口 W，比如说最近选中的 10 个物品 W，用 W 代替 MMR 公式里面的 S

$MMR: \displaystyle\argmax_{i \in R}\{\theta \cdot reward_i - (1 - \theta) \cdot \displaystyle \max_{j \in W} sim(i, j)\}$

因为已经是重排阶段了，所以这个顺序已经是用户会看到的顺序。离得很远的两个物品相似不会太影响用户的体验

## 重排业务规则

- 最多连续出现 k = 5 篇图文笔记，最多连续出现 k = 5 篇视频笔记
- 每 k = 9 篇笔记最多出现一篇运营推广笔记（boost），boost 的笔记的精排分数会乘上一个大于 1 的系数
- 排名前 t = 4 篇最容易被看到（首屏），对用户体验最重要，最多只能出现 k = 1 篇电商笔记。第 t = 1 篇笔记最多出现 k = 0 篇电商笔记
- 结合 MMR：选择下一篇之前，我们用规则排除掉 $R$ 中的部分物品得到子集 $R'$

## Determinantal Point Process 行列式点过程

超平形体：
- 2维超平形体是平行四边形，平行四边形里面的点可以表示为 $x = \alpha_1v_1 + \alpha_2v_2, \alpha_1, \alpha_2 \in [0, 1]$
- 3维超平形体是平行六面体，平行六面体里面的点可以表示为 $x = \alpha_1v_1 + \alpha_2v_2+ \alpha_3v_3, \alpha_1, \alpha_2, \alpha_3 \in [0, 1]$
- k维超平形体：$P(v_1, ..., v_k) = \{ \alpha_1 v_1 + ... + \alpha_kv_k | 0 \leq \alpha_1, ..., \alpha_k \leq 1\}, k \leq d$，要求 $v_1, ..., v_k$ 线性不相关

体积和行列式：
- 给定 k 个物品，把它们表征成单位向量 $v_1, ..., v_k \in R^d, d \geq k$
- 用超平形体的体积来衡量物品的多样性，体积介于0和1
- 如果两两正交，体积最大化是1
- 如果线性相关，则体积最小化是0
- 如果把这些单位向量作为矩阵 $V \in R^{d \times k}$ 的列，那么行列式和体积满足 $det(V^TV) = vol(P(v_1, ..., v_k))^2$，因此可以用行列式来衡量向量的多样性（有推导）

多样性
- $\displaystyle\argmax_{S: |S| = k} \theta \cdot (\displaystyle\sum_{j \in S}reward_j) + (1 - \theta) \cdot \log det(V_S^TV_S)$
- 但是直接这么算会有问题，因为组合优化问题（从集合中选出一个大小为k的子集）是 NP-hard
- 实践中用贪心算法求解，S 是已选中的物品，R 是未选中的物品，求 $\displaystyle\argmax_{i \in R} \theta \cdot reward_i + (1 - \theta) \cdot \log det(A_{S \cup \{i\}})$
- 如果暴力计算行列式，那么总时间复杂度是 $O(|S|^3 \cdot |R| \cdot k) = O(nk^4)$，整个算法的总时间复杂度是 $O(n^2d + nk^4)$
- Hulu 的算法使用了 Cholesky 分解来计算所有的行列式，使得时间复杂度变成 $O(n^2d + nk^2)$，可以在 10 ms 内完成（有推导）

# 物品冷启动

UGC 物品的冷启动：良莠不齐，量太大没办法用人工分发

为什么要特殊对待新笔记？
- 新笔记缺少和用户的交互，导致推荐难度大，效果差
- 扶持新发布，低曝光的笔记，可以增强作者的积极性

目标：
- 精准推荐：把新笔记推荐给合适的用户，不引起用户的反感
- 激励发布：流量向低曝光新笔记倾斜，激励作者发布
- 挖掘高潜：通过初期小流量的试探，找到高质量笔记，给更多的流量

评价指标：
- 作者侧指标：
  - 发布渗透率 penetration rate $= \frac{当日发布人数}{日活人数}$
  - 人均发布量 $= \frac{当日发布的笔记数}{日活人数}$，会比渗透率大，因为会有人一天发好几篇
- 用户侧指标：
  - 新笔记：点击率，交互率，
    - 但是曝光的基尼系数很大，少量的头部新笔记占据了绝大多数的曝光
    - 所以应当分别考察高曝光，低曝光的新笔记（小于一千次的曝光）
  - 大盘指标：消费时长，日活，月活
    - 避免大幅度伤害到这些指标而不是提升这些指标
    - 大力扶持低曝光笔记的结果：作者侧发布指标变好，用户侧大盘消费指标变差
- 内容侧指标：高热笔记占比
  - 高热笔记的定义：前30天获得1000次点击
  - 高热笔记占比越高，说明冷启动挖掘优质笔记的能力越强

## 召回冷启动

- 没有用户交互：itemCF 不发挥作用
- 笔记 id embedding 没有意义：因为学习 embedding 是需要交互数据的，所以双塔模型没学好。双塔模型比 itemCF 更重要，可以改造后处理冷启动
- 类目，关键词召回：适用

### 改造双塔模型

- 新笔记使用 default embedding，也就是说所有的新笔记都共享这一个 ID 而不是自己真正的 ID，这样的话比随机的 embedding 要好
- 利用相似笔记的 embedding 向量：多模态找到内容最类似的 k 篇高曝光笔记，然后 average pooling 作为新笔记的 embedding
- 多个向量召回池：1小时新笔记，6小时新笔记，24小时新笔记，30天笔记，因为使用同一个双塔模型，所以不会增加召回的代价

### 类目召回

- 类目索引：类目 $\rightarrow$ 笔记列表
- 类目召回：用户画像 $\rightarrow$ 类目 $\rightarrow$ 笔记列表（取回最新的 k 篇）
- 缺点：
  - 只对刚刚发布的新笔记有效，取回某类目/关键词下最新的 k 篇笔记，那么发布了几个小时之后就不可能再被召回
  - 弱个性化，不够精准：类目/关键词太宽泛

### 聚类召回

- 假设用户喜欢某一篇笔记，那么相似内容的笔记他也会喜欢
- 训练一个神经网络，输入笔记的类目和图文内容，输出特征向量
- 对笔记向量做聚类，划分成 1000 cluster，记录每一个 cluster 的中心方向（可以用 k-means 聚类，用余弦相似度）

新索引
- 一篇新笔记发布之后，用这个神经网络把它映射成一个特征向量
- 和1000个中心特征向量比较，找到最相似的向量，作为新笔记的 cluster
- 索引： cluster $\rightarrow$ 笔记 id 列表（按时间倒排）

线上召回
- 给定用户 id，找到 last-n 交互笔记
- 使用神经网络映射这些笔记，找最相似的 cluster
- 在 cluster 的笔记列表中取回最新的 m 篇笔记：最多取回 mn 篇新笔记

内容相似度模型
- 提取图文特征：CNN 将图片变成向量，BERT 将文字变成向量，concatenate 之后输入 FCN 得到笔记的特征向量
- 两篇笔记的相似度可以通过计算这两个笔记的特征向量的余弦相似度
- 训练：
  - 正样本笔记 $b^+$，种子笔记 $a$，负样本笔记 $b^-$，鼓励 $\cos(a, b^+) > \cos(a, b^-)$
  - 使用双塔模型的 Triplet hinge loss: $L(a, b^+, b^-) = \max\{0, \cos(a, b^-) + m - cos(a, b^+)\}$
  - 也可以使用双塔模型的 Triplet logistic loss: $L(a, b^+, b^-) = log(1 + e^{\sigma(\cos(a, b^-)- cos(a, b^+))})$, $\sigma$ 是控制损失函数形状的超参数
- 选正样本：
  - 人工标注二元组的相似度
  - 算法选择：
    - 高曝光的笔记作为二元组（有充足用户交互信息），两篇笔记有相同的二级类目
    - 用 itemCF 的物品相似度来选正样本
- 选负样本：
  - 全体物品中随机选：字数较多的，质量较高的（避免图文无关）

### look-alike 人群扩散召回

起源互联网广告：
- 完全符合条件的称为种子用户（万）
- 比如说特斯拉的典型用户是年龄 25-35，本科以上，关注科技数码，喜欢苹果的电子产品
- 但是这些信息很多人都没填，我们要人群扩散找到这些潜在用户（十万）

如何定义两个用户的相似度：
- UserCF
- embedding cos 较大

对于新笔记来说：
- 我们计算一个有交互的用户的向量的平均作为特征向量
- 近线更新特征向量：分钟级更新
- 每当有用户交互该物品，更新特征向量

流程：
- 和新笔记有交互的用户是种子用户：用look-alike 在相似用户中扩散
- 当用户刷新小红书，用他的向量在向量数据库里做最近邻查找，取回几十篇笔记
- 是一种特殊的 userCF，因为新的 item 的 embedding 学习不充分，但是交互的用户很可能 embedding 学习是很充分的
- 区别在于 userCF 是使用这个用户最相似的 top-k 个用户和他们最近交互过的 n 个物品，但是 look-alike 是专注于新笔记的所有交互用户（这些用户不一定是 top-k 相似用户，但是他们的 average pooling 相似就行）

## 流量调控

如果推荐系统只分发年龄小于30天的笔记，使用自然分发会使得新笔记（年龄小于24小时）的曝光占比为$\frac{1}{30}$，但实际上工业界会使新笔记的曝光占比远大于 $\frac{1}{30}$

发展：
1. 推荐结果强插新笔记：落伍
2. 对新笔记的排序分数提权 boost：抖音，小红书
3. 通过提权，对新笔记做保量（使得每篇新笔记在前24小时有100次曝光）
4. 差异化保量，内容质量高给更多的保量

新笔记提权：
- 人为干涉粗排和重排，因为这两个环节是漏斗（会筛选）
- 优点：容易实现，投入产出好
- 缺点：曝光量对提权系数很敏感，很难精确控制，容易过度曝光或者不充分曝光

新笔记保量：
- 在原有的提权系数上，乘以额外的提权系数，差的越多，提权系数越大
- 可以设计这样的一个函数来计算 $提权系数 =f(\frac{发布时间}{目标时间}, \frac{已有曝光}{目标曝光})$
- 难点：保量成功率远低于 100%，线上环境变化会使得保量失败（新增召回通道，升级排序模型，改变重排打散的规则）所以需要调整提权系数
- 如果给很大的提权系数？更容易完成保量，但是笔记会被推荐给不合适的受众（指标会变差，热门笔记一直被打压）

| 发布时间 \ 当前曝光次数 | 0-24 | 25-49 | 50-74 | 75-100 |
| -------------------- | --- | ------ | ---- | ------- |
| 0-5 h | 1 | 1 | 1 | 1 |
| 6-11 h | 1.1 | 1 | 1 | 1 |
| 12-17 h | 1.2 | 1.1 | 1 | 1 |
| 18-24 h | 1.3 | 1.2 | 1.1 | 1 |

差异化保量：
- 基础保量：24小时100次曝光
- 内容质量：模型判断，上限加200次曝光
- 作者质量：按作者历史的笔记质量，上限加200次曝光

动态提权有点像广告领域的平滑消费（投放曲线）

## 冷启动的 AB test

用户侧：如果我们用差异化保量的话，那么实验组（不得不）看到了更多的新笔记，消费指标变差，对照组看到了更少的新笔记，消费指标变好。这样两者之间的差异就会比实际上更大

作者侧：

- 只对新笔记分成两组：按作者分成各 50%，一半用新的冷启动策略，另一半用老的冷启动策略
  - 新笔记之间会抢流量：
    - 假设新老笔记之间没有竞争，新笔记永远都是 $\frac{1}{3}$ 的流量
    - 比如说新策略是将新笔记的权重增大2倍，AB test 的时候实验组因为权重高抢了对照组的新笔记的曝光量，但是推全之后 diff 会消失
  - 新笔记会和老笔记抢流量：
    - 假设新老笔记自由竞争
    - 比如说新策略是将新笔记的权重增大2倍，AB 测试的时候只有 50% 的新笔记在和 100% 老笔记抢流量，推全就会有 100% 的新笔记和 100% 老笔记抢流量（进步 diff变成 AB test 的一半）
- 用户也分成两组：50% 用户只能看到 50% 的新笔记，另外 50% 用户只能看到另外 50% 的新笔记
  - 这样推荐的笔记是在全体笔记中选，现在是在一半里面选，也就是说为了做测试影响了大盘数据，用户体验变差
  - 优势：新笔记互相不抢流量，实验结果更可信
  - 缺点：新笔记仍会和老笔记抢流量，AB 测试结果会比推全之后好
- 把老笔记也切成两半，相当于分成了两个 app（老笔记，新笔记，用户）
  - diff 最准确，但是这样最影响用户体验，不现实

# 涨指标

主要关注日活用户数 DAU 和留存 (LT7, LT30)
- LT 的定义是某个用户今天登录了 APP，未来 n 天有几天登录了 APP 就等于几，显然 $1 \leq LT7 \leq 7, 1 \leq LT30 \leq 30$
- LT 增加通常意味着用户体验，除非 DAU 下降了（极限情况：假设低活用户禁止登陆，那么 DAU 下降，LT 增长）
- 其他核心指标：用户使用时长，总阅读数/点击数，总曝光数，这些指标重要性低于 DAU 和留存
  - 时长增加：LT 通常增加，阅读数，曝光数可能会下降
- UGC 平台：发布量和发布渗透率也是核心指标
- 非核心指标：点击率，交互率

## 召回

- 推荐系统有几十条召回通道，召回总量是固定的（比如五千），总量越大，效果越好，粗排的计算量越大
- 双塔模型 two tower 和 item to item I2I 是最重要的两个召回模型，占据召回的大部分配额
- 很多小众的模型，配额很少，召回总量不变的前提下可以提升核心指标
- 同一个模型可以用在多个内容池，得到多条召回通道
  - 内容池：30天物品，一天物品，6小时物品，新用户优质内容池，分人群内容池

优化双塔模型：
- 改进正样本，负样本：简单正样本（有点击的），简单负样本（随机的），困难负样本（排序靠后的）
- 改进神经网络：
  - 用户塔和物品塔用深度交叉网络DCN代替全连接网络FCN
  - 在用户塔使用用户行为序列 last-n
  - 使用多向量模型代替标准的单向量模型：假设我们需要点击率，点赞率，收藏率，那么用户塔返回的特征向量是物品塔返回的3倍，然后计算内积/cos相似度来预估点击率，点赞率，收藏率
    - 为什么多向量只用在用户塔而不在物品塔？因为物品太多了，如果需要10个指标就需要10个向量数据库，代价太大
- 改进训练方法：
  - baseline：是做二分类，让模型区分正负样本
  - 改进：
    - batch 内负采样
    - 使用自监督学习，更好地学冷门物品的 embedding

优化 I2I 模型：
- 是一大类模型，基于相似物品做召回
- 最常见是 U2I2I：用户喜欢物品 $i_1$，寻找 物品 $i_1$ 的相似物品 $i_2$
- 物品相似度怎么计算？
  - ItemCF, Online ItemCF, Swing, Online Swing 都是基于用户同时喜欢物品 $i_1$ 和 $i_2$ 来判断相似
  - 用物品的向量表征，计算向量的相似度：用双塔模型或者 GNN
- 线上一般要同时使用这些模型：Online ItemCF, Swing, Online Swing，各分配一定的配额（超参数，需要调）

小众的召回模型：
- U2U2I(UserCF)：已知用户 $u_1, u_2$ 相似，而且 $u_2$ 喜欢物品 i，那么也给 $u_1$ 推荐物品 i
- U2A2I(作者召回)：已知用户 u 喜欢作者 a，a 发布了物品 i，给用户 u 推荐物品 i
- U2A2A2I(相似作者召回)：已知用户喜欢作者 $a_1$，而且作者 $a_1$ 与 $a_2$ 相似，$a_2$ 发布物品 i，给用户推荐物品 i
- Path based Deep Network (PDN)
- Deep Retrieval
- Sparse-Interest Network (SINE)
- Multi-task Multi-view Graph Representation Learning (M2GRL)

## 排序

$$
\left.
\begin{array}{c}
用户特征\\
物品特征\\
统计特征\\
场景特征
\end{array}
\right \}
\rightarrow 
\left.
\begin{array}{c}
\text{embedding FCN}\\
\text{shared bottom} 基座\\
\text{concatenate}
\end{array}
\right.
 \rightarrow
\left \{
\begin{array}{c}
全连接层 \times 2 + \text{Sigmoid} \rightarrow 点击率\\
全连接层 \times 2 + \text{Sigmoid} \rightarrow 点赞率\\
全连接层 \times 2 + \text{Sigmoid} \rightarrow 收藏率\\
全连接层 \times 2 + \text{Sigmoid} \rightarrow 转发率
\end{array}
\right.
$$

基座优化：
- 加宽加深（1-6 层），计算量更大，预测更准
- 自动特征交叉：bilinear, LHUC
- 特征工程：添加统计特征，多模态内容特征

多目标预估：
- 新增预估目标：进入评论区，给别人的评论点赞
- MMoE，PLE：可能有效，往往无效
- position de-bias：可能有效，往往无效

粗排模型优化：
- 打分量大10倍，所以必须够快，三塔就不错（三塔比多向量双塔要好）
- 蒸馏 distill 精排训练粗排，让粗排和精排更一致
  - pointwise: y 是真实行为，p 是精排的预估，粗排拟合 $\frac{y + p}{2}$
  - pairwise/ listwise: 
    - 粗排模型 learning to rank LTR 学习精排模型预测的物品**顺序**而不是给定的评分
    - 也就是说粗排学习的是 $p_i > p_j$ 不然有惩罚，一般用 pairwise logistic loss
- 优点：粗排精排一致性建模很显著能提升效果，一般来说 pointwise 就足够了，pairwise 和 listwise 大厂里面会用
- 缺点：如果精排出了bug（流程太长，可能是infra的问题）预估不准，那么就会污染粗排导致指标持续缓慢下降（不易察觉）

用户行为序列建模：
- 对 last-n 物品向量做平均作为用户特征
- DIN 注意力机制，加权平均
- 最流行方法：SIM 类目筛选之后再做 DIN 加权平均
- 改进1：增加序列长度，预测会更准确，但是非常考验系统的架构（快手一百万，小红书一千），增加计算成本和推理时间
- 改进2：筛选类目/物品向量聚类：降低序列长度
- 改进3：增加物品除了id以外的特征（不能加太多，影响性能）

在线学习（增量更新）主要是精排
- 凌晨需要全量更新，全天不间断增量更新
- 因为要做 AB test，所以线上有 m 个模型，需要 m 套在线模型（一个 holdout，一个推全，m-2 个新模型）
- 每套机器成本都很高(10000 CPU core)，所以m很小(6)
- 在线学习对指标提升很大，但会制约模型开发迭代的效率（过早开始在线学习会把模型锁死在较弱的版本）

老汤模型
- 因为老模型每天都用新产生的数据做 1 epoch 的训练，久而久之，它被训练得非常好，很难被超过
- 如何判断新老模型的好坏？
  - 新老模型都随机初始化 FCN，embedding 可以随机初始化，也可以复用老模型的
  - 用 10 天左右的数据训练新老模型，新模型如果显著优于老模型，那么它很可能更优
  - 不需要追上线上老模型，只需要结构更优（10天训练的新模型不可能追平老模型）
- 如何更快追平超过老模型？
  - 复用 embedding 层
  - 初期用老模型蒸馏
  - 目标：几十天的数据能追上百天老模型

## 多样性

精排多样性：结合兴趣分数和多样性分数
- $s_i$：兴趣分数，融合点击率等多个预估目标
- $d_i$：多样性分数，物品 i 和已选中物品的差异，用MMR，DPP来计算，精排使用滑动窗口（粗排不用，因为要考虑整体而不是一个窗口的多样性）
- 用 $s_i + d_i$ 来对物品做排序
- 打散策略：
  - 规则限制：相同类目之间要隔 5 个位置以上
  - 多模态：将全库物品聚类成 1000 类，精排阶段同一聚类之间要隔 10 个位置以上

粗排多样性：
- 比如说要选出500个物品进入精排
  - 对 5000 个物品的 $s_i$ 排序，分数最高的 200 个物品送入精排
  - 对剩余的 4800 个物品 $s_i + d_i$ 排序，分数最高的 300 个物品送入精排

召回多样性：
- 双塔模型：添加噪音
  - 在计算出用户向量之后，做ANN检索之前，往用户向量中添加随机噪声（高斯）
  - 用户的兴趣越窄（last-n 的类目越少），则要添加越多的噪声
  - 添加噪音看起来会让推送更不准，但实践中因为召回的物品更多样，会提升推荐系统的核心指标
- 双塔模型：抽样用户行为序列
  - 最近交互的 n 个物品，只保留最近的 r 个，然后在剩余的 n-r 个物品中随机抽样 t 个物品（可以均匀抽样，也可以非均匀抽样让类目平衡）
  - 将得到的 r+t 个物品作为用户行为序列，而不用全部的 n 个物品
  - 优点1：这样用户连续刷新也可以召回很不一样的结果，注入随机性，召回结果更多样化
  - 优点2：可以利用起来用户很久之前的兴趣

U2I2I (ItemCF) 多样性：
- 种子物品的类目少，而且不平衡
- 所以可以做非均匀随机抽样，在 n 个物品中选出 t 个，让类目平衡
- 类目更平衡，多样性更好
- n 可以很大，覆盖更多的类目

流量探索：
- 曝光物品中有 2% 是非个性化的，用作兴趣探索
- 维护精选内容池，里面都是交互率指标很高的优质物品（可以分人群，比如说30-40男）
- 随机抽样物品，跳过排序，直接插入最终的精排结果（因为不提权或者强插就会被排序算法过滤掉）
- 短期内会负面影响核心指标，但是长期是有利的

## 特殊用户群体

为什么？
- 新用户、低活用户行为少，个性化推荐不准确
- 新用户、低活用户容易流失，留存是最重要的，其他指标不重要
- 特殊用户的行为不同于主流用户，基于全体用户行为训练出来的模型在特殊用户上有偏差（喜欢留评论的中年女性：做一个促进评论的内容池）

构造特殊内容池：
- 方法1:根据物品的交互次数，交互率来选择优质物品
  - 人群：比如18-25岁一线城市男性
  - 内容池有弱个性化的效果，定期更新，加入新物品，去掉交互率低，失去时效性的老物品，只对该人群生效
- 方法2:因果推断
  - 判断物品对于留存率的贡献，根据贡献来选择物品（工业界技术未成熟）

特殊内容池召回：
- 用双塔模型来做召回
- 双塔模型对新用户不准，但是内容本身高质量，低个性化，所以问题不大
- 额外的训练代价？不会
  - 不管使用什么内容池，老用户都是用同一个双塔模型在召回
  - 新用户使用一个输入参数更少的双塔模型，同样只需要一个双塔模型
- 额外的推理代价？对的
  - 内容池更新之后，也要更新 ANN 的索引
  - 线上召回的时候，要做 ANN 检索
  - 因为特殊内容池是全量内容池的 $\frac{1}{10}$ 到 $\frac{1}{100}$，所以额外算力不太大

特殊排序策略：
- 排除低质量物品：
  - 对于新用户、低活用户，业务上只关注留存，不关注消费（曝光量，广告收入，电商收入）
  - 所以要少出广告，不出广告
  - 新发布的物品冷启动不在新用户、低活用户上探索
    - 推荐不准会损害用户体验
    - 只在活跃的老用户上做探索，对新物品提权 boost
- 差异化的融分公式：关注点击
  - 新用户、低活用户的点击，交互不同于正常用户
  - 他们的点击量很少，没有点击就更没有进一步的交互
  - 增加低活用户融分公式的点击率权重
  - 保留几个曝光位置给预估点击率最高的几个物品（甚至直接把点击率最高的物品放在第一，确保用户看到，确实有效，但是只对低活用户）
- 差异化的排序模型：
  - 大模型 + 小模型：
    - 全体用户行为训练大模型（6 层 FCN）
    - 特殊用户的行为训练小模型（2 层 FCN），$q$ 拟合残差 $y - p$
    - 特殊用户才会用这个 $p + q$
  - 融合多个 experts，类似于 MMoE
    - MMoE 有一个小神经网络，输入：全部的特征，输出：专家的权重
    - 这里是只用用户的特征作为输入（这里的特征就包括新老，活跃度等特征），而不是全部的特征
  - 大模型预估，小模型校准
    - 用大模型预估点击率，交互率
    - 小模型（可以非常小，比如GBDT）将用户特征（是不是新用户，活跃度）和大模型预估的点击率，交互率作为输入
    - 小模型的输出拟合特殊人群，更准确
- 错误：
  - 每种人群有一个排序模型，推荐系统同时维护多个大模型：全体用户数据全量更新主模型，在特殊人群的数据上再训练 1 epoch 作为该用户人群的模型
    - 短期提升指标，维护代价大，长期有害（成本太高）

## 利用交互行为

最简单的方法：将模型预估的交互率用于排序

关注：
- 关注的作者越多，则平台对他吸引力越强
- 用户留存率 r 和关注的作者数量 f 正相关
- 方法1:用排序策略提升关注量
  - 用户 u，对物品 i 的关注率预测为 $p_i$，用户关注了 f 个作者，定义单调递减函数 $w(f)$，融分公式加入 $w(f) \cdot p_i$ 来促进关注
- 方法2:促进关注的内容池和召回通道
  - 做一个内容池，里面的物品关注率高
  - 如果用户关注的作者数少，则使用该内容池
  - 召回配额可以固定也可以和 f 负相关

粉丝数对促发布的价值：
- UGC 平台希望作者发布量大，发布率高
- 交互可以提升作者发布的积极性，增加粉丝会提升作者发布积极性
- 用排序策略帮低粉丝新作者涨粉
  - 作者 a 发布的物品 i 可能会被推荐给用户 u，模型预测的关注率是 $p_{ui}$
  - 定义单调递减函数 $w(f_a)$ 作为权重，作者 a 粉丝越多，权重越小
  - 在排序的融分公式里面加入 $w(f_a) \cdot p_{ui}$

隐式关注关系：
- U2A2I 用户 u 有可能喜欢看但是没有/忘了关注作者 a
- 所以应当挖掘这种关系，然后也定义成关注的作者

转发：
- 吸引站外流量，可以提升 DAU 和消费指标
- 但是简单提升转发会负面影响其他指标
- 如何尽量吸引站外流量呢？其他平台的 Key Opinion Leader (KOL)，不一定是本平台的 KOL
- 如何判断这个人是不是别的平台的 KOL 呢？看历史转发带来的点击数据就知道了
- 方法1:融分公式增加 $k_u \cdot p_{ui}$，$k_u$ 是用户在站外的影响力（普通人接近0，不干扰排序），$p_{ui}$ 是模型预估的转发率
- 方法2:促转发内容池和召回通道，只对站外KOL生效

评论：
- 促发布，关注和评论会提升作者积极性
- 新发布物品如果没有评论，则给预估评论率提权：融分公式增加 $w_i \cdot p_i$ 权重和已有评论数量负相关
- 给喜欢留评论的用户推需要促进评论的内容池，那么双方都可能有更多互动
- 有的用户评论很高质量（点赞高）：对作者和其他的用户留存有贡献，鼓励这些用户留评论